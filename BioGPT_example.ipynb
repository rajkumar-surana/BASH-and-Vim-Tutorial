{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajkumar-surana/BASH-and-Vim-Tutorial/blob/main/BioGPT_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# requirements and installation"
      ],
      "metadata": {
        "id": "IRJoCoAPEZaz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH4NQnKqRaCM",
        "outputId": "95831791-1bc2-4092-dc90-ba372dcc680e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BioGPT'...\n",
            "remote: Enumerating objects: 391, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 391 (delta 71), reused 49 (delta 48), pack-reused 293\u001b[K\n",
            "Receiving objects: 100% (391/391), 31.45 MiB | 25.93 MiB/s, done.\n",
            "Resolving deltas: 100% (210/210), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/microsoft/BioGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BioGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcARlUZteLb0",
        "outputId": "5421bff3-7a6d-4b48-ab8e-bc6fdb70b020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUScH_iodNaY",
        "outputId": "1404c0a0-ddd9-4804-cdd9-0a229d15b6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34544, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 34544 (delta 0), reused 1 (delta 0), pack-reused 34543\u001b[K\n",
            "Receiving objects: 100% (34544/34544), 24.04 MiB | 28.89 MiB/s, done.\n",
            "Resolving deltas: 100% (25101/25101), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHw4djuqdQge",
        "outputId": "99d821dd-b3ce-473f-d605-9f70662c9df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT/fairseq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout v0.12.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhQT7QpCdSYJ",
        "outputId": "0aa6dd32-cceb-4dc7-a989-54b38dff3cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: switching to 'v0.12.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 6795311b 0.12.0 release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojONYkchdWEF",
        "outputId": "4ab2e474-36b0-4916-9be6-3af0fa203e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/BioGPT/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.0) (1.22.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.0) (2022.10.31)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.0) (1.15.1)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray\n",
            "  Downloading bitarray-2.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.6/269.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.0) (0.29.34)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from fairseq==0.12.0) (4.65.0)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.9/dist-packages (from omegaconf<2.1->fairseq==0.12.0) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from omegaconf<2.1->fairseq==0.12.0) (4.5.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.0) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.0) (0.8.10)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->fairseq==0.12.0) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->fairseq==0.12.0) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->fairseq==0.12.0) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->fairseq==0.12.0) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->fairseq==0.12.0) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->fairseq==0.12.0) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->fairseq==0.12.0) (3.25.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi->fairseq==0.12.0) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->fairseq==0.12.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->fairseq==0.12.0) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.0-cp39-cp39-linux_x86_64.whl size=11173861 sha256=a7f14ee27a9d0527619851ef1d8e630e5ffc795a7ab64501691635cbce23c45c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v39okmx_/wheels/3d/eb/5c/2601718fd4ae1dbca3ea178a7531be88123b4a5348183d00ab\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=37f0e3d56e312b6ba30d7d81b069336686b8c5b972e277af1cc0353940f96a8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/3c/ae/14db087e6018de74810afe32eb6ac890ef9c68ba19b00db97a\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.3 colorama-0.4.6 fairseq-0.12.0 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDufwRRydV9z",
        "outputId": "f2eed2ac-2cc0-43fc-d902-161f4a0eb9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/setuptools/__init__.py:85: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated. Requirements should be satisfied by a PEP 517 installer. If you are using pip, you can try `pip install --use-pep517`.\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "running build_ext\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "skipping 'fairseq/data/data_utils_fast.cpp' Cython extension (up-to-date)\n",
            "skipping 'fairseq/data/token_block_utils_fast.cpp' Cython extension (up-to-date)\n",
            "building 'fairseq.libbase' extension\n",
            "creating build/temp.linux-x86_64-3.9/fairseq/clib/libbase\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/include/python3.9 -c fairseq/clib/libbase/balanced_assignment.cpp -o build/temp.linux-x86_64-3.9/fairseq/clib/libbase/balanced_assignment.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/fairseq/clib/libbase/balanced_assignment.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/libbase.cpython-39-x86_64-linux-gnu.so\n",
            "building 'fairseq.libnat' extension\n",
            "creating build/temp.linux-x86_64-3.9/fairseq/clib/libnat\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/include/python3.9 -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-3.9/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/fairseq/clib/libnat/edit_dist.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/libnat.cpython-39-x86_64-linux-gnu.so\n",
            "building 'alignment_train_cpu_binding' extension\n",
            "creating build/temp.linux-x86_64-3.9/examples\n",
            "creating build/temp.linux-x86_64-3.9/examples/operators\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/include/python3.9 -c examples/operators/alignment_train_cpu.cpp -o build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cpu.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/alignment_train_cpu_binding.cpython-39-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.9/fairseq/libbleu.cpython-39-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.9/fairseq/data/data_utils_fast.cpython-39-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.cpython-39-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.9/fairseq/libbase.cpython-39-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.9/fairseq/libnat.cpython-39-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.9/alignment_train_cpu_binding.cpython-39-x86_64-linux-gnu.so -> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvizXIm8fDVq",
        "outputId": "ca9b2a66-0efe-494c-b0e9-27941a0e8cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PWD = '/content'\n",
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3iYtHnjjchoz",
        "outputId": "02e9ced7-5069-4844-8b1c-30d9eb76e31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/moses-smt/mosesdecoder.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dIoiHJydV0A",
        "outputId": "aa5fc080-9709-4dfe-a821-61613d251606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mosesdecoder'...\n",
            "remote: Enumerating objects: 148097, done.\u001b[K\n",
            "remote: Counting objects: 100% (525/525), done.\u001b[K\n",
            "remote: Compressing objects: 100% (229/229), done.\u001b[K\n",
            "remote: Total 148097 (delta 323), reused 441 (delta 292), pack-reused 147572\u001b[K\n",
            "Receiving objects: 100% (148097/148097), 129.88 MiB | 14.31 MiB/s, done.\n",
            "Resolving deltas: 100% (114349/114349), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export MOSES=${PWD}/mosesdecode"
      ],
      "metadata": {
        "id": "jjfDigd4er-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/glample/fastBPE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV1rlidXezID",
        "outputId": "eb15ec4f-fc7a-4f23-b393-71b8d2df0eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastBPE'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "Unpacking objects:   1% (1/59)\rUnpacking objects:   3% (2/59)\rUnpacking objects:   5% (3/59)\rUnpacking objects:   6% (4/59)\rUnpacking objects:   8% (5/59)\rUnpacking objects:  10% (6/59)\rUnpacking objects:  11% (7/59)\rUnpacking objects:  13% (8/59)\rUnpacking objects:  15% (9/59)\rUnpacking objects:  16% (10/59)\rUnpacking objects:  18% (11/59)\rUnpacking objects:  20% (12/59)\rUnpacking objects:  22% (13/59)\rUnpacking objects:  23% (14/59)\rUnpacking objects:  25% (15/59)\rUnpacking objects:  27% (16/59)\rUnpacking objects:  28% (17/59)\rUnpacking objects:  30% (18/59)\rUnpacking objects:  32% (19/59)\rUnpacking objects:  33% (20/59)\rUnpacking objects:  35% (21/59)\rUnpacking objects:  37% (22/59)\rremote: Total 59 (delta 0), reused 0 (delta 0), pack-reused 59\u001b[K\n",
            "Unpacking objects:  38% (23/59)\rUnpacking objects:  40% (24/59)\rUnpacking objects:  42% (25/59)\rUnpacking objects:  44% (26/59)\rUnpacking objects:  45% (27/59)\rUnpacking objects:  47% (28/59)\rUnpacking objects:  49% (29/59)\rUnpacking objects:  50% (30/59)\rUnpacking objects:  52% (31/59)\rUnpacking objects:  54% (32/59)\rUnpacking objects:  55% (33/59)\rUnpacking objects:  57% (34/59)\rUnpacking objects:  59% (35/59)\rUnpacking objects:  61% (36/59)\rUnpacking objects:  62% (37/59)\rUnpacking objects:  64% (38/59)\rUnpacking objects:  66% (39/59)\rUnpacking objects:  67% (40/59)\rUnpacking objects:  69% (41/59)\rUnpacking objects:  71% (42/59)\rUnpacking objects:  72% (43/59)\rUnpacking objects:  74% (44/59)\rUnpacking objects:  76% (45/59)\rUnpacking objects:  77% (46/59)\rUnpacking objects:  79% (47/59)\rUnpacking objects:  81% (48/59)\rUnpacking objects:  83% (49/59)\rUnpacking objects:  84% (50/59)\rUnpacking objects:  86% (51/59)\rUnpacking objects:  88% (52/59)\rUnpacking objects:  89% (53/59)\rUnpacking objects:  91% (54/59)\rUnpacking objects:  93% (55/59)\rUnpacking objects:  94% (56/59)\rUnpacking objects:  96% (57/59)\rUnpacking objects:  98% (58/59)\rUnpacking objects: 100% (59/59)\rUnpacking objects: 100% (59/59), 29.97 KiB | 807.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export FASTBPE=${PWD}/fastBPE"
      ],
      "metadata": {
        "id": "waQLusuTe1z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fastBPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nglH_QOHfblj",
        "outputId": "5f4c8356-45f5-4dd4-ce6f-8ebeacafda81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT/fastBPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast"
      ],
      "metadata": {
        "id": "qDmlk4SNe1rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73A2HD2RfJqr",
        "outputId": "791a1523-7fe5-4f32-d0eb-1a2a81cc35e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/880.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/880.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m870.4/880.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacremoses) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sacremoses) (4.65.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=0025358d440b9db93b2d2a079144cfa35e91334cef6184deb198fbbca492fcb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbc3MvqYfJXw",
        "outputId": "505cd9a2-eedc-4c4a-eabd-7129133a33af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastBPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1kObN8zb2or",
        "outputId": "9affed63-9bc8-454f-c4d1-936cb6503b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastBPE\n",
            "  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fastBPE\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp39-cp39-linux_x86_64.whl size=762548 sha256=3aaa3a32e5687f1929dc9419a5f5d190fed3f525bca521846a62f08c462baa71\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/10/20/0691b69b472ff8530a7e608674d5bd1cbc772f4d6071c8accf\n",
            "Successfully built fastBPE\n",
            "Installing collected packages: fastBPE\n",
            "Successfully installed fastBPE-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# use pre-trained BioGPT model"
      ],
      "metadata": {
        "id": "GTwAvoZeHmIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BioGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79CuAHjwHumu",
        "outputId": "c8ce9f59-f3a1-4cda-e432-cb89f360b757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from fairseq.models.transformer_lm import TransformerLanguageModel\n",
        "m = TransformerLanguageModel.from_pretrained(\n",
        "        \"checkpoints/Pre-trained-BioGPT\", \n",
        "        \"checkpoint.pt\", \n",
        "        \"data\",\n",
        "        tokenizer='moses', \n",
        "        bpe='fastbpe', \n",
        "        bpe_codes=\"data/bpecodes\",\n",
        "        min_len=100,\n",
        "        max_len_b=1024)\n",
        "m.cuda()\n",
        "src_tokens = m.encode(\"Streptococcus pneumoniae can through \")\n",
        "generate = m.generate([src_tokens], beam=5)[0]\n",
        "output = m.decode(generate[0][\"tokens\"])\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "fVg93RoIHlCg",
        "outputId": "8c61b14f-93da-47c3-e0ab-466f0b013294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5b7863753d94>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_lm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m m = TransformerLanguageModel.from_pretrained(\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"checkpoints/Pre-trained-BioGPT\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"checkpoint.pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from src.transformer_lm_prompt import TransformerLanguageModelPrompt\n",
        "m = TransformerLanguageModelPrompt.from_pretrained(\n",
        "        \"checkpoints/RE-DTI-BioGPT\", \n",
        "        \"checkpoint_avg.pt\", \n",
        "        \"data/KD-DTI/relis-bin\",\n",
        "        tokenizer='moses', \n",
        "        bpe='fastbpe', \n",
        "        bpe_codes=\"data/bpecodes\",\n",
        "        max_len_b=1024,\n",
        "        beam=1)\n",
        "m.cuda()\n",
        "src_text=\"\" # input text, e.g., a PubMed abstract\n",
        "src_tokens = m.encode(src_text)\n",
        "generate = m.generate([src_tokens], beam=args.beam)[0]\n",
        "output = m.decode(generate[0][\"tokens\"])\n",
        "print(output)"
      ],
      "metadata": {
        "id": "qTk3xPiQHQsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# question answering (PubMedQA)"
      ],
      "metadata": {
        "id": "_G4kGdGdk8ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BioGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmMKApYufkKK",
        "outputId": "95d6d75e-c7f1-4d13-9c53-59317a203609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints"
      ],
      "metadata": {
        "id": "PAlxz2hBfvEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZm9ymZmgrJd",
        "outputId": "9728ef30-8fb6-4a5f-a5de-75b1afeb7750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT/checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/Pre-trained-BioGPT.tgz\n",
        "!tar -zxvf Pre-trained-BioGPT.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmCCA1efidwx",
        "outputId": "04f504ca-cd6a-4eda-df2c-423b2fe37a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-18 10:09:43--  https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/Pre-trained-BioGPT.tgz\n",
            "Resolving msramllasc.blob.core.windows.net (msramllasc.blob.core.windows.net)... 20.209.34.164\n",
            "Connecting to msramllasc.blob.core.windows.net (msramllasc.blob.core.windows.net)|20.209.34.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3414384105 (3.2G) [application/octet-stream]\n",
            "Saving to: ‘Pre-trained-BioGPT.tgz’\n",
            "\n",
            "Pre-trained-BioGPT. 100%[===================>]   3.18G  26.8MB/s    in 99s     \n",
            "\n",
            "2023-04-18 10:11:23 (32.8 MB/s) - ‘Pre-trained-BioGPT.tgz’ saved [3414384105/3414384105]\n",
            "\n",
            "Pre-trained-BioGPT/\n",
            "Pre-trained-BioGPT/checkpoint.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/QA-PubMedQA-BioGPT.tgz\n",
        "!tar -zxvf QA-PubMedQA-BioGPT.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BU9Ia7Zf0tR",
        "outputId": "7a15651b-823b-49dd-a1df-bd28655d430c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-18 10:12:14--  https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/QA-PubMedQA-BioGPT.tgz\n",
            "Resolving msralaphilly2.blob.core.windows.net (msralaphilly2.blob.core.windows.net)... 52.239.193.100\n",
            "Connecting to msralaphilly2.blob.core.windows.net (msralaphilly2.blob.core.windows.net)|52.239.193.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3419713292 (3.2G) [application/octet-stream]\n",
            "Saving to: ‘QA-PubMedQA-BioGPT.tgz’\n",
            "\n",
            "QA-PubMedQA-BioGPT. 100%[===================>]   3.18G  33.8MB/s    in 1m 59s  \n",
            "\n",
            "2023-04-18 10:14:14 (27.3 MB/s) - ‘QA-PubMedQA-BioGPT.tgz’ saved [3419713292/3419713292]\n",
            "\n",
            "QA-PubMedQA-BioGPT/\n",
            "QA-PubMedQA-BioGPT/checkpoint.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJcum28ggruK",
        "outputId": "5a4b3093-2ee0-4c4f-ba47-f1440b99017d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4pVNabZFTa9",
        "outputId": "f9369776-8de8-4acf-d082-7ab412ca0a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu117, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1vWIz0OFWqy",
        "outputId": "93dbd3bb-8eca-420d-dae3-0a6d6dd1909a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.0.0+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SB3NE53PunE",
        "outputId": "e6e36254-f586-455d-d345-a5acea00ad81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pubmedqa/pubmedqa.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTXKj2BtR6PH",
        "outputId": "b0a79533-6228-44f6-d7cb-1919afa90ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmedqa'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (37/37), 703.20 KiB | 3.02 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pubmedqa/preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Dkv-0QfwKW",
        "outputId": "6ba6b774-9f0c-4fda-bfd1-cc3b56ff788e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pubmedqa/preprocess\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python split_dataset.py pqal"
      ],
      "metadata": {
        "id": "5QnthBPbb0su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pubmedqa/data/pqal_fold0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dymq_hLxg92A",
        "outputId": "c582892c-3cc1-4185-89fa-59d445a23f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pubmedqa/data/pqal_fold0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp train_set.json /content/BioGPT/data/PubMedQA/raw"
      ],
      "metadata": {
        "id": "clWddqxUYdE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp dev_set.json /content/BioGPT/data/PubMedQA/raw"
      ],
      "metadata": {
        "id": "qEt313zEhapq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjtzBJcJhenl",
        "outputId": "17968829-6fdd-46b0-ec74-a958d88e954d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pubmedqa/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp test_ground_truth.json /content/BioGPT/data/PubMedQA/raw\n",
        "!cp test_set.json /content/BioGPT/data/PubMedQA/raw"
      ],
      "metadata": {
        "id": "9xOMpDRuhgOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BioGPT/examples/QA-PubMedQA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqCF821Jh0D9",
        "outputId": "aa34b3d4-ea1e-406e-820d-2083ae3e93d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT/examples/QA-PubMedQA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash preprocess.sh # for BioGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MvHYu9EZT2l",
        "outputId": "56debf78-a393-4f93-88d6-cf53fcc5f933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "450 samples in ../../data/PubMedQA/raw/train_set.json has been processed\n",
            "50 samples in ../../data/PubMedQA/raw/dev_set.json has been processed\n",
            "500 samples in ../../data/PubMedQA/raw/test_set.json has been processed\n",
            "Preprocessing train\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Loading codes from ../../data/PubMedQA/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/PubMedQA/raw/pqal_qcl_ansis_train.tok.x ...\n",
            "Read 120494 words (11402 unique) from text file.\n",
            "Applying BPE to ../../data/PubMedQA/raw/pqal_qcl_ansis_train.tok.x ...\n",
            "Modified 120494 words from text file.\n",
            "Loading codes from ../../data/PubMedQA/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/PubMedQA/raw/pqal_qcl_ansis_train.tok.y ...\n",
            "Read 4950 words (11 unique) from text file.\n",
            "Applying BPE to ../../data/PubMedQA/raw/pqal_qcl_ansis_train.tok.y ...\n",
            "Modified 4950 words from text file.\n",
            "Preprocessing valid\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Loading codes from ../../data/PubMedQA/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/PubMedQA/raw/pqal_qcl_ansis_valid.tok.x ...\n",
            "Read 13477 words (2897 unique) from text file.\n",
            "Applying BPE to ../../data/PubMedQA/raw/pqal_qcl_ansis_valid.tok.x ...\n",
            "Modified 13477 words from text file.\n",
            "Loading codes from ../../data/PubMedQA/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/PubMedQA/raw/pqal_qcl_ansis_valid.tok.y ...\n",
            "Read 550 words (11 unique) from text file.\n",
            "Applying BPE to ../../data/PubMedQA/raw/pqal_qcl_ansis_valid.tok.y ...\n",
            "Modified 550 words from text file.\n",
            "Preprocessing test\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Loading codes from ../../data/PubMedQA/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/PubMedQA/raw/pqal_qcl_ansis_test.tok.x ...\n",
            "Read 137067 words (12522 unique) from text file.\n",
            "Applying BPE to ../../data/PubMedQA/raw/pqal_qcl_ansis_test.tok.x ...\n",
            "Modified 137067 words from text file.\n",
            "Loading codes from ../../data/PubMedQA/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/PubMedQA/raw/pqal_qcl_ansis_test.tok.y ...\n",
            "Read 5500 words (11 unique) from text file.\n",
            "Applying BPE to ../../data/PubMedQA/raw/pqal_qcl_ansis_test.tok.y ...\n",
            "Modified 5500 words from text file.\n",
            "2023-04-18 10:18:26.195137: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-18 10:18:27.086519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-18 10:18:29 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='x', target_lang='y', trainpref='../../data/PubMedQA/raw/pqal_qcl_ansis_train.tok.bpe', validpref='../../data/PubMedQA/raw/pqal_qcl_ansis_valid.tok.bpe', testpref='../../data/PubMedQA/raw/pqal_qcl_ansis_test.tok.bpe', align_suffix=None, destdir='../../data/PubMedQA/pqal_qcl_ansis-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../../data/PubMedQA/raw/dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=8, dict_only=False)\n",
            "2023-04-18 10:18:29 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n",
            "2023-04-18 10:18:30 | INFO | fairseq_cli.preprocess | [x] ../../data/PubMedQA/raw/pqal_qcl_ansis_train.tok.bpe.x: 450 sents, 126865 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-18 10:18:30 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n",
            "2023-04-18 10:18:30 | INFO | fairseq_cli.preprocess | [x] ../../data/PubMedQA/raw/pqal_qcl_ansis_valid.tok.bpe.x: 50 sents, 14180 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-18 10:18:30 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n",
            "2023-04-18 10:18:31 | INFO | fairseq_cli.preprocess | [x] ../../data/PubMedQA/raw/pqal_qcl_ansis_test.tok.bpe.x: 500 sents, 144271 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-18 10:18:31 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n",
            "2023-04-18 10:18:32 | INFO | fairseq_cli.preprocess | [y] ../../data/PubMedQA/raw/pqal_qcl_ansis_train.tok.bpe.y: 450 sents, 5449 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-18 10:18:32 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n",
            "2023-04-18 10:18:32 | INFO | fairseq_cli.preprocess | [y] ../../data/PubMedQA/raw/pqal_qcl_ansis_valid.tok.bpe.y: 50 sents, 606 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-18 10:18:32 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n",
            "2023-04-18 10:18:32 | INFO | fairseq_cli.preprocess | [y] ../../data/PubMedQA/raw/pqal_qcl_ansis_test.tok.bpe.y: 500 sents, 6055 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-18 10:18:32 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../../data/PubMedQA/pqal_qcl_ansis-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash infer.sh # for BioGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI0pWzVjiUQg",
        "outputId": "d90ae2a8-e8ec-4c2c-934f-a52585865345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin inferencing /content/BioGPT/examples/QA-PubMedQA/../../data/PubMedQA/raw/pqal_qcl_ansis_test.tok.bpe.x using ../../checkpoints/QA-PubMedQA-BioGPT/checkpoint.pt\n",
            "2023-04-18 10:18:39.690309: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-18 10:18:41.062049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-18 10:18:43 | INFO | fairseq.file_utils | loading archive file ../../checkpoints/QA-PubMedQA-BioGPT\n",
            "2023-04-18 10:18:43 | INFO | fairseq.file_utils | loading archive file /content/BioGPT/examples/QA-PubMedQA/../../data/PubMedQA/pqal_qcl_ansis-bin\n",
            "2023-04-18 10:18:48 | INFO | src.language_modeling_prompt | dictionary: 42384 types\n",
            "2023-04-18 10:18:54 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../src', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 12000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/QA-PubMedQA-BioGPT-ReasoningRequest', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '../../checkpoints/QA-PubMedQA-BioGPT-ReasoningRequest-finalstage/checkpoint10.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'save_after_epoch': 0, 'no_best_checkpoints': True}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 1024, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_prompt_biogpt', 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 24, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': True, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'decoder_xformers_att_config': None, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': 1024, 'tpu': False}, 'task': {'_name': 'language_modeling_prompt', 'data': '/content/BioGPT/examples/QA-PubMedQA/../../data/PubMedQA/pqal_qcl_ansis-bin', 'sample_break_mode': 'none', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': 1024, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'source_lang': None, 'target_lang': None, 'max_source_positions': 900, 'manual_prompt': None, 'learned_prompt': 9, 'learned_prompt_pattern': 'learned', 'prefix': False, 'sep_token': '<seqsep>'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 100, 'warmup_init_lr': 1e-07, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../src', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 12000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/QA-PubMedQA-BioGPT-ReasoningRequest', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '../../checkpoints/QA-PubMedQA-BioGPT-ReasoningRequest-finalstage/checkpoint10.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'save_after_epoch': 0, 'no_best_checkpoints': True}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 1024, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_prompt_biogpt', 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 24, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': True, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'decoder_xformers_att_config': None, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': 1024, 'tpu': False}, 'task': {'_name': 'language_modeling_prompt', 'data': '/content/BioGPT/examples/QA-PubMedQA/../../data/PubMedQA/pqal_qcl_ansis-bin', 'sample_break_mode': 'none', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': 1024, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'source_lang': None, 'target_lang': None, 'max_source_positions': 900, 'manual_prompt': None, 'learned_prompt': 9, 'learned_prompt_pattern': 'learned', 'prefix': False, 'sep_token': '<seqsep>'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 100, 'warmup_init_lr': 1e-07, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "Converting to float 16\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 1\n",
            "failed = 0, total = 500\n",
            "\n",
            "====File:  generate_checkpoint.pt.detok.extracted.txt\n",
            "0.782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# document classification (HoC)"
      ],
      "metadata": {
        "id": "mWtBwpvlkBEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BioGPT/checkpoints\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fhGFwpV0jyZ",
        "outputId": "ff912043-c840-4713-ba94-99141473f785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT/checkpoints\n",
            "Pre-trained-BioGPT\tQA-PubMedQA-BioGPT\t  QA-PubMedQA-BioGPT.tgz\n",
            "Pre-trained-BioGPT.tgz\tQA-PubMedQA-BioGPT-Large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/DC-HoC-BioGPT.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isnpHDZS00ii",
        "outputId": "d830ddd0-b75d-4ff8-d80b-fe5a66a32e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-12 05:49:17--  https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/DC-HoC-BioGPT.tgz\n",
            "Resolving msramllasc.blob.core.windows.net (msramllasc.blob.core.windows.net)... 20.209.34.164\n",
            "Connecting to msramllasc.blob.core.windows.net (msramllasc.blob.core.windows.net)|20.209.34.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3967598329 (3.7G) [application/octet-stream]\n",
            "Saving to: ‘DC-HoC-BioGPT.tgz’\n",
            "\n",
            "DC-HoC-BioGPT.tgz   100%[===================>]   3.69G  37.3MB/s    in 1m 50s  \n",
            "\n",
            "2023-04-12 05:51:07 (34.5 MB/s) - ‘DC-HoC-BioGPT.tgz’ saved [3967598329/3967598329]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zxvf DC-HoC-BioGPT.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plJ0__zk03Sj",
        "outputId": "aecaddfe-1103-4274-eac3-68589365f72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DC-HoC-BioGPT/\n",
            "DC-HoC-BioGPT/checkpoint_last.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BioGPT/examples/DC-HoC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGdtHsdh06uC",
        "outputId": "1847aa39-3025-43fd-d143-2c3b1133c2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT/examples/DC-HoC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash preprocess_1.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYaGzDArkDph",
        "outputId": "ef7dd62d-d141-4949-db49-eeae9af72aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9972 samples in ../../data/HoC/raw/train.tsv has been processed\n",
            "4947 samples in ../../data/HoC/raw/valid.tsv has been processed\n",
            "4947 samples in ../../data/HoC/raw/test.tsv has been processed\n",
            "Preprocessing train\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Loading codes from ../../data/HoC/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/HoC/raw/ansis_train.tok.x ...\n",
            "Read 286241 words (16148 unique) from text file.\n",
            "Applying BPE to ../../data/HoC/raw/ansis_train.tok.x ...\n",
            "Modified 286241 words from text file.\n",
            "Loading codes from ../../data/HoC/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/HoC/raw/ansis_train.tok.y ...\n",
            "Read 88331 words (38 unique) from text file.\n",
            "Applying BPE to ../../data/HoC/raw/ansis_train.tok.y ...\n",
            "Modified 88331 words from text file.\n",
            "Preprocessing valid\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Loading codes from ../../data/HoC/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/HoC/raw/ansis_valid.tok.x ...\n",
            "Read 141964 words (10776 unique) from text file.\n",
            "Applying BPE to ../../data/HoC/raw/ansis_valid.tok.x ...\n",
            "Modified 141964 words from text file.\n",
            "Loading codes from ../../data/HoC/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/HoC/raw/ansis_valid.tok.y ...\n",
            "Read 43965 words (38 unique) from text file.\n",
            "Applying BPE to ../../data/HoC/raw/ansis_valid.tok.y ...\n",
            "Modified 43965 words from text file.\n",
            "Preprocessing test\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "Loading codes from ../../data/HoC/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/HoC/raw/ansis_test.tok.x ...\n",
            "Read 141964 words (10776 unique) from text file.\n",
            "Applying BPE to ../../data/HoC/raw/ansis_test.tok.x ...\n",
            "Modified 141964 words from text file.\n",
            "Loading codes from ../../data/HoC/raw/bpecodes ...\n",
            "Read 40000 codes from the codes file.\n",
            "Loading vocabulary from ../../data/HoC/raw/ansis_test.tok.y ...\n",
            "Read 43965 words (38 unique) from text file.\n",
            "Applying BPE to ../../data/HoC/raw/ansis_test.tok.y ...\n",
            "Modified 43965 words from text file.\n",
            "2023-04-12 05:52:26.730983: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-12 05:52:27.754847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-12 05:52:30 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='x', target_lang='y', trainpref='../../data/HoC/raw/ansis_train.tok.bpe', validpref='../../data/HoC/raw/ansis_valid.tok.bpe', testpref='../../data/HoC/raw/ansis_test.tok.bpe', align_suffix=None, destdir='../../data/HoC/ansis-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../../data/HoC/raw/dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=8, dict_only=False)\n",
            "2023-04-12 05:52:31 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n",
            "2023-04-12 05:52:34 | INFO | fairseq_cli.preprocess | [x] ../../data/HoC/raw/ansis_train.tok.bpe.x: 9972 sents, 314357 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-12 05:52:34 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n",
            "2023-04-12 05:52:35 | INFO | fairseq_cli.preprocess | [x] ../../data/HoC/raw/ansis_valid.tok.bpe.x: 4947 sents, 156057 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-12 05:52:35 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n",
            "2023-04-12 05:52:37 | INFO | fairseq_cli.preprocess | [x] ../../data/HoC/raw/ansis_test.tok.bpe.x: 4947 sents, 156057 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-12 05:52:37 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n",
            "2023-04-12 05:52:38 | INFO | fairseq_cli.preprocess | [y] ../../data/HoC/raw/ansis_train.tok.bpe.y: 9972 sents, 99287 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-12 05:52:38 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n",
            "2023-04-12 05:52:40 | INFO | fairseq_cli.preprocess | [y] ../../data/HoC/raw/ansis_valid.tok.bpe.y: 4947 sents, 49424 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-12 05:52:40 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n",
            "2023-04-12 05:52:40 | INFO | fairseq_cli.preprocess | [y] ../../data/HoC/raw/ansis_test.tok.bpe.y: 4947 sents, 49424 tokens, 0.0% replaced (by <unk>)\n",
            "2023-04-12 05:52:40 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../../data/HoC/ansis-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash train.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr-8RZjs0Uha",
        "outputId": "ebb4e1ed-2865-4103-e9c9-06c0cb883451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-12 05:52:44.036308: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-12 05:52:44.908120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-12 05:52:46 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2023-04-12 05:52:48 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../src', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 20000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/DC-HoC-BioGPT', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '../../checkpoints/Pre-trained-BioGPT/checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_prompt_biogpt', 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 24, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': True, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'decoder_xformers_att_config': None, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': 1024, 'tpu': False}, 'task': {'_name': 'language_modeling_prompt', 'data': '../../data/HoC/ansis-bin', 'sample_break_mode': none, 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': 1024, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'source_lang': None, 'target_lang': None, 'max_source_positions': 900, 'manual_prompt': None, 'learned_prompt': 1, 'learned_prompt_pattern': 'learned', 'prefix': False, 'sep_token': '<seqsep>'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 1000, 'warmup_init_lr': 1e-07, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-04-12 05:52:48 | INFO | src.language_modeling_prompt | dictionary: 42384 types\n",
            "2023-04-12 05:52:53 | INFO | fairseq_cli.train | TransformerLanguageModelPrompt(\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(42385, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=1024, out_features=42385, bias=False)\n",
            "  )\n",
            ")\n",
            "2023-04-12 05:52:53 | INFO | fairseq_cli.train | task: LanguageModelingPromptTask\n",
            "2023-04-12 05:52:53 | INFO | fairseq_cli.train | model: TransformerLanguageModelPrompt\n",
            "2023-04-12 05:52:53 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion\n",
            "2023-04-12 05:52:53 | INFO | fairseq_cli.train | num. shared model params: 346,764,288 (num. trained: 346,764,288)\n",
            "2023-04-12 05:52:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2023-04-12 05:52:53 | INFO | fairseq.data.data_utils | loaded 4,947 examples from: ../../data/HoC/ansis-bin/valid.x-y.x\n",
            "2023-04-12 05:52:53 | INFO | fairseq.data.data_utils | loaded 4,947 examples from: ../../data/HoC/ansis-bin/valid.x-y.y\n",
            "2023-04-12 05:53:02 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2023-04-12 05:53:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-04-12 05:53:02 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2023-04-12 05:53:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-04-12 05:53:02 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2023-04-12 05:53:02 | INFO | fairseq_cli.train | max tokens per device = 1024 and max sentences per device = None\n",
            "2023-04-12 05:53:02 | INFO | fairseq.trainer | Preparing to load checkpoint ../../checkpoints/DC-HoC-BioGPT/checkpoint_last.pt\n",
            "2023-04-12 05:53:24 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp\n",
            "2023-04-12 05:53:26 | INFO | fairseq.trainer | Loaded checkpoint ../../checkpoints/DC-HoC-BioGPT/checkpoint_last.pt (epoch 1251 @ 20000 updates)\n",
            "2023-04-12 05:53:26 | INFO | fairseq.trainer | loading train data for epoch 1251\n",
            "2023-04-12 05:53:26 | INFO | fairseq.data.data_utils | loaded 9,972 examples from: ../../data/HoC/ansis-bin/train.x-y.x\n",
            "2023-04-12 05:53:26 | INFO | fairseq.data.data_utils | loaded 9,972 examples from: ../../data/HoC/ansis-bin/train.x-y.y\n",
            "2023-04-12 05:53:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 16\n",
            "epoch 1251:   0% 0/16 [00:00<?, ?it/s]2023-04-12 05:53:26 | INFO | fairseq.trainer | begin training epoch 1251\n",
            "2023-04-12 05:53:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "2023-04-12 05:53:46 | INFO | fairseq_cli.train | Stopping training due to num_updates: 20001 >= max_update: 20000\n",
            "2023-04-12 05:53:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 1251 | valid on 'valid' subset:   0% 0/244 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   0% 1/244 [00:00<01:52,  2.16it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   1% 2/244 [00:00<01:14,  3.23it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   1% 3/244 [00:00<01:05,  3.71it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   2% 4/244 [00:01<00:58,  4.13it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   2% 5/244 [00:01<00:56,  4.27it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   2% 6/244 [00:01<00:53,  4.49it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   3% 7/244 [00:01<00:51,  4.63it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   3% 8/244 [00:01<00:49,  4.72it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   4% 9/244 [00:02<00:49,  4.74it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   4% 10/244 [00:02<00:50,  4.60it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   5% 11/244 [00:02<00:51,  4.56it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   5% 12/244 [00:02<00:51,  4.55it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   5% 13/244 [00:02<00:48,  4.73it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   6% 14/244 [00:03<00:47,  4.86it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   6% 15/244 [00:03<00:46,  4.95it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   7% 16/244 [00:03<00:45,  5.02it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   7% 17/244 [00:03<00:44,  5.04it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   7% 18/244 [00:03<00:44,  5.10it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   8% 19/244 [00:04<00:43,  5.12it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   8% 20/244 [00:04<00:43,  5.10it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   9% 21/244 [00:04<00:43,  5.09it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   9% 22/244 [00:04<00:44,  5.04it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:   9% 23/244 [00:04<00:43,  5.03it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  10% 24/244 [00:05<00:44,  4.99it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  10% 25/244 [00:05<00:43,  5.01it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  11% 26/244 [00:05<00:43,  4.99it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  11% 27/244 [00:05<00:43,  4.95it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  11% 28/244 [00:05<00:43,  4.94it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  12% 29/244 [00:06<00:43,  4.92it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  12% 30/244 [00:06<00:43,  4.92it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  13% 31/244 [00:06<00:43,  4.89it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  13% 32/244 [00:06<00:43,  4.88it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  14% 33/244 [00:06<00:43,  4.87it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  14% 34/244 [00:07<00:43,  4.88it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  14% 35/244 [00:07<00:42,  4.88it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  15% 36/244 [00:07<00:42,  4.85it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  15% 37/244 [00:07<00:42,  4.84it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  16% 38/244 [00:08<00:42,  4.85it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  16% 39/244 [00:08<00:42,  4.86it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  16% 40/244 [00:08<00:42,  4.86it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  17% 41/244 [00:08<00:43,  4.71it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  17% 42/244 [00:08<00:44,  4.58it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  18% 43/244 [00:09<00:44,  4.52it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  18% 44/244 [00:09<00:45,  4.44it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  18% 45/244 [00:09<00:44,  4.44it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  19% 46/244 [00:09<00:41,  4.75it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  19% 47/244 [00:09<00:39,  4.98it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  20% 48/244 [00:10<00:38,  5.15it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  20% 49/244 [00:10<00:36,  5.31it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  20% 50/244 [00:10<00:35,  5.45it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  21% 51/244 [00:10<00:35,  5.51it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  21% 52/244 [00:10<00:34,  5.53it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  22% 53/244 [00:10<00:34,  5.59it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  22% 54/244 [00:11<00:34,  5.53it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  23% 55/244 [00:11<00:34,  5.50it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  23% 56/244 [00:11<00:34,  5.50it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  23% 57/244 [00:11<00:34,  5.47it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  24% 58/244 [00:11<00:34,  5.42it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  24% 59/244 [00:12<00:34,  5.39it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  25% 60/244 [00:12<00:34,  5.39it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  25% 61/244 [00:12<00:33,  5.40it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  25% 62/244 [00:12<00:33,  5.39it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  26% 63/244 [00:12<00:33,  5.36it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  26% 64/244 [00:13<00:33,  5.33it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  27% 65/244 [00:13<00:33,  5.31it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  27% 66/244 [00:13<00:33,  5.31it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  27% 67/244 [00:13<00:33,  5.33it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  28% 68/244 [00:13<00:33,  5.32it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  28% 69/244 [00:13<00:33,  5.28it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  29% 70/244 [00:14<00:33,  5.27it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  29% 71/244 [00:14<00:32,  5.24it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  30% 72/244 [00:14<00:32,  5.27it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  30% 73/244 [00:14<00:32,  5.27it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  30% 74/244 [00:14<00:32,  5.23it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  31% 75/244 [00:15<00:32,  5.16it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  31% 76/244 [00:15<00:33,  5.09it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  32% 77/244 [00:15<00:32,  5.07it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  32% 78/244 [00:15<00:32,  5.06it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  32% 79/244 [00:15<00:32,  5.06it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  33% 80/244 [00:16<00:32,  5.06it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  33% 81/244 [00:16<00:32,  5.02it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  34% 82/244 [00:16<00:32,  4.99it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  34% 83/244 [00:16<00:32,  4.95it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  34% 84/244 [00:16<00:32,  4.95it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  35% 85/244 [00:17<00:32,  4.97it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  35% 86/244 [00:17<00:31,  4.97it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  36% 87/244 [00:17<00:31,  4.95it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  36% 88/244 [00:17<00:31,  4.93it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  36% 89/244 [00:17<00:31,  4.92it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  37% 90/244 [00:18<00:31,  4.92it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  37% 91/244 [00:18<00:30,  4.96it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  38% 92/244 [00:18<00:30,  4.95it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  38% 93/244 [00:18<00:30,  4.92it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  39% 94/244 [00:18<00:30,  4.92it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  39% 95/244 [00:19<00:30,  4.92it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  39% 96/244 [00:19<00:29,  4.94it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  40% 97/244 [00:19<00:29,  4.93it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  40% 98/244 [00:19<00:29,  4.92it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  41% 99/244 [00:19<00:29,  4.89it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  41% 100/244 [00:20<00:29,  4.88it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  41% 101/244 [00:20<00:29,  4.88it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  42% 102/244 [00:20<00:29,  4.88it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  42% 103/244 [00:20<00:28,  4.87it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  43% 104/244 [00:21<00:28,  4.85it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  43% 105/244 [00:21<00:28,  4.84it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  43% 106/244 [00:21<00:29,  4.70it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  44% 107/244 [00:21<00:29,  4.58it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  44% 108/244 [00:21<00:30,  4.47it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  45% 109/244 [00:22<00:30,  4.41it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  45% 110/244 [00:22<00:30,  4.38it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  45% 111/244 [00:22<00:30,  4.37it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  46% 112/244 [00:22<00:27,  4.82it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  46% 113/244 [00:22<00:25,  5.17it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  47% 114/244 [00:23<00:23,  5.44it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  47% 115/244 [00:23<00:22,  5.71it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  48% 116/244 [00:23<00:21,  5.88it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  48% 117/244 [00:23<00:21,  6.03it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  48% 118/244 [00:23<00:21,  5.99it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  49% 119/244 [00:23<00:20,  6.12it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  49% 120/244 [00:24<00:19,  6.20it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  50% 121/244 [00:24<00:19,  6.27it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  50% 122/244 [00:24<00:19,  6.29it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  50% 123/244 [00:24<00:19,  6.31it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  51% 124/244 [00:24<00:19,  6.27it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  51% 125/244 [00:24<00:18,  6.28it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  52% 126/244 [00:24<00:18,  6.33it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  52% 127/244 [00:25<00:18,  6.33it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  52% 128/244 [00:25<00:18,  6.32it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  53% 129/244 [00:25<00:18,  6.27it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  53% 130/244 [00:25<00:18,  6.28it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  54% 131/244 [00:25<00:17,  6.30it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  54% 132/244 [00:25<00:17,  6.35it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  55% 133/244 [00:26<00:17,  6.35it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  55% 134/244 [00:26<00:17,  6.31it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  55% 135/244 [00:26<00:17,  6.27it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  56% 136/244 [00:26<00:17,  6.26it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  56% 137/244 [00:26<00:17,  6.21it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  57% 138/244 [00:26<00:17,  6.18it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  57% 139/244 [00:27<00:16,  6.19it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  57% 140/244 [00:27<00:16,  6.19it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  58% 141/244 [00:27<00:16,  6.21it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  58% 142/244 [00:27<00:16,  6.17it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  59% 143/244 [00:27<00:16,  6.16it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  59% 144/244 [00:27<00:16,  6.16it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  59% 145/244 [00:28<00:16,  6.18it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  60% 146/244 [00:28<00:16,  5.99it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  60% 147/244 [00:28<00:16,  5.84it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  61% 148/244 [00:28<00:16,  5.70it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  61% 149/244 [00:28<00:16,  5.62it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  61% 150/244 [00:28<00:16,  5.61it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  62% 151/244 [00:29<00:16,  5.59it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  62% 152/244 [00:29<00:16,  5.57it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  63% 153/244 [00:29<00:16,  5.52it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  63% 154/244 [00:29<00:16,  5.47it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  64% 155/244 [00:29<00:16,  5.48it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  64% 156/244 [00:30<00:15,  5.52it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  64% 157/244 [00:30<00:15,  5.51it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  65% 158/244 [00:30<00:15,  5.49it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  65% 159/244 [00:30<00:15,  5.47it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  66% 160/244 [00:30<00:15,  5.46it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  66% 161/244 [00:30<00:15,  5.46it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  66% 162/244 [00:31<00:15,  5.46it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  67% 163/244 [00:31<00:14,  5.45it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  67% 164/244 [00:31<00:14,  5.41it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  68% 165/244 [00:31<00:14,  5.36it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  68% 166/244 [00:31<00:14,  5.36it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  68% 167/244 [00:32<00:14,  5.37it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  69% 168/244 [00:32<00:14,  5.25it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  69% 169/244 [00:32<00:14,  5.20it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  70% 170/244 [00:32<00:14,  5.15it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  70% 171/244 [00:32<00:14,  5.13it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  70% 172/244 [00:33<00:14,  5.12it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  71% 173/244 [00:33<00:13,  5.09it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  71% 174/244 [00:33<00:13,  5.07it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  72% 175/244 [00:33<00:13,  5.02it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  72% 176/244 [00:33<00:13,  5.03it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  73% 177/244 [00:34<00:13,  5.05it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  73% 178/244 [00:34<00:13,  5.04it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  73% 179/244 [00:34<00:12,  5.01it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  74% 180/244 [00:34<00:12,  4.96it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  74% 181/244 [00:34<00:12,  4.96it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  75% 182/244 [00:35<00:12,  4.97it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  75% 183/244 [00:35<00:12,  4.94it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  75% 184/244 [00:35<00:12,  4.89it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  76% 185/244 [00:35<00:12,  4.84it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  76% 186/244 [00:35<00:12,  4.80it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  77% 187/244 [00:36<00:11,  4.80it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  77% 188/244 [00:36<00:11,  4.77it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  77% 189/244 [00:36<00:11,  4.76it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  78% 190/244 [00:36<00:11,  4.71it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  78% 191/244 [00:36<00:11,  4.70it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  79% 192/244 [00:37<00:11,  4.71it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  79% 193/244 [00:37<00:10,  4.67it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  80% 194/244 [00:37<00:10,  4.66it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  80% 195/244 [00:37<00:10,  4.66it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  80% 196/244 [00:38<00:10,  4.65it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  81% 197/244 [00:38<00:10,  4.66it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  81% 198/244 [00:38<00:09,  4.66it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  82% 199/244 [00:38<00:09,  4.64it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  82% 200/244 [00:38<00:09,  4.63it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  82% 201/244 [00:39<00:09,  4.63it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  83% 202/244 [00:39<00:09,  4.59it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  83% 203/244 [00:39<00:09,  4.43it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  84% 204/244 [00:39<00:09,  4.30it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  84% 205/244 [00:39<00:07,  5.00it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  84% 206/244 [00:40<00:06,  5.65it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  85% 207/244 [00:40<00:05,  6.28it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  85% 208/244 [00:40<00:05,  6.77it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  86% 209/244 [00:40<00:04,  7.07it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  86% 210/244 [00:40<00:04,  7.37it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  86% 211/244 [00:40<00:04,  7.59it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  87% 212/244 [00:40<00:04,  7.89it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  87% 213/244 [00:40<00:03,  7.93it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  88% 214/244 [00:41<00:03,  7.95it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  88% 215/244 [00:41<00:03,  7.96it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  89% 216/244 [00:41<00:03,  7.96it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  89% 217/244 [00:41<00:03,  7.97it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  89% 218/244 [00:41<00:03,  8.00it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  90% 219/244 [00:41<00:03,  8.04it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  90% 220/244 [00:41<00:02,  8.06it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  91% 221/244 [00:41<00:02,  8.04it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  91% 222/244 [00:42<00:02,  8.02it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  91% 223/244 [00:42<00:02,  8.03it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  92% 224/244 [00:42<00:02,  8.07it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  92% 225/244 [00:42<00:02,  8.07it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  93% 226/244 [00:42<00:02,  8.11it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  93% 227/244 [00:42<00:02,  8.11it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  93% 228/244 [00:42<00:01,  8.13it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  94% 229/244 [00:42<00:01,  8.05it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  94% 230/244 [00:43<00:01,  8.06it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  95% 231/244 [00:43<00:01,  7.37it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  95% 232/244 [00:43<00:01,  6.93it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  95% 233/244 [00:43<00:01,  6.69it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  96% 234/244 [00:43<00:01,  6.50it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  96% 235/244 [00:43<00:01,  6.36it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  97% 236/244 [00:44<00:01,  6.35it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  97% 237/244 [00:44<00:01,  6.30it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  98% 238/244 [00:44<00:00,  6.25it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  98% 239/244 [00:44<00:00,  5.94it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  98% 240/244 [00:44<00:00,  5.76it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  99% 241/244 [00:44<00:00,  5.46it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset:  99% 242/244 [00:45<00:00,  5.26it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset: 100% 243/244 [00:45<00:00,  5.04it/s]\u001b[A\n",
            "epoch 1251 | valid on 'valid' subset: 100% 244/244 [00:45<00:00,  5.63it/s]\u001b[A\n",
            "                                                                           \u001b[A2023-04-12 05:54:32 | INFO | valid | epoch 1251 | valid on 'valid' subset | loss 5.78 | ppl 54.95 | wps 4537.8 | wpb 842.1 | bsz 20.3 | num_updates 20001 | best_loss 2.96\n",
            "2023-04-12 05:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1251 @ 20001 updates\n",
            "2023-04-12 05:54:32 | INFO | fairseq.trainer | Saving checkpoint to /content/BioGPT/checkpoints/DC-HoC-BioGPT/checkpoint_last.pt\n",
            "2023-04-12 05:54:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/BioGPT/checkpoints/DC-HoC-BioGPT/checkpoint_last.pt\n",
            "2023-04-12 05:54:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../../checkpoints/DC-HoC-BioGPT/checkpoint_last.pt (epoch 1251 @ 20001 updates, score 5.78) (writing took 22.338492072000008 seconds)\n",
            "2023-04-12 05:54:54 | INFO | fairseq_cli.train | end of epoch 1251 (average epoch stats below)\n",
            "2023-04-12 05:54:54 | INFO | train | epoch 1251 | loss 0.337 | ppl 1.26 | wps 0 | ups 0 | wpb 27823 | bsz 680 | num_updates 20001 | lr 2.23601e-06 | gnorm 0.191 | train_wall 20 | gb_free 7.3 | wall 113\n",
            "2023-04-12 05:54:54 | INFO | fairseq_cli.train | done training in 88.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash infer_Hoc.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iElbXCm74lO_",
        "outputId": "60b52b99-13d4-40f8-a266-9759e63eb0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 1\n",
            "failed = 0, total = 4947\n",
            "\n",
            "====File:  generate_checkpoint_last.pt.detok.extracted.txt\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['activating invasion and metastasis &amp; # 124 ; avoiding immune destruction', 'activating invasion and metastasis &amp; # 124 ; cellular energetics', 'activating invasion and metastasis &amp; # 124 ; evading growth suppressors', 'activating invasion and metastasis &amp; # 124 ; genomic instability and mutation', 'activating invasion and metastasis &amp; # 124 ; sustaining proliferative signaling', 'enabling replicative immortality &amp; # 124 ; genomic instability and mutation', 'enabling replicative immortality &amp; # 124 ; sustaining proliferative signaling', 'evading growth suppressors &amp; # 124 ; activating invasion and metastasis', 'evading growth suppressors &amp; # 124 ; enabling replicative immortality', 'evading growth suppressors &amp; # 124 ; genomic instability and mutation', 'evading growth suppressors &amp; # 124 ; sustaining proliferative signaling', 'genomic instability and mutation &amp; # 124 ; activating invasion and metastasis', 'genomic instability and mutation &amp; # 124 ; sustaining proliferative signaling', 'inducing angiogenesis &amp; # 124 ; activating invasion and metastasis', 'inducing angiogenesis &amp; # 124 ; sustaining proliferative signaling', 'inducing angiogenesis &amp; # 124 ; tumor promoting inflammation', 'resisting cell death &amp; # 124 ; activating invasion and metastasis', 'resisting cell death &amp; # 124 ; activating invasion and metastasis &amp; # 124 ; sustaining proliferative signaling', 'resisting cell death &amp; # 124 ; avoiding immune destruction', 'resisting cell death &amp; # 124 ; cellular energetics', 'resisting cell death &amp; # 124 ; enabling replicative immortality', 'resisting cell death &amp; # 124 ; enabling replicative immortality &amp; # 124 ; sustaining proliferative signaling', 'resisting cell death &amp; # 124 ; evading growth suppressors', 'resisting cell death &amp; # 124 ; evading growth suppressors &amp; # 124 ; sustaining proliferative signaling', 'resisting cell death &amp; # 124 ; genomic instability and mutation', 'resisting cell death &amp; # 124 ; inducing angiogenesis', 'resisting cell death &amp; # 124 ; inducing angiogenesis &amp; # 124 ; evading growth suppressors &amp; # 124 ; sustaining proliferative signaling', 'resisting cell death &amp; # 124 ; sustaining proliferative signaling', 'resisting cell death &amp; # 124 ; tumor promoting inflammation', 'resisting cell death &amp; # 124 ; tumor promoting inflammation &amp; # 124 ; activating invasion and metastasis', 'resisting cell death &amp; # 124 ; tumor promoting inflammation &amp; # 124 ; genomic instability and mutation', 'tumor promoting inflammation &amp; # 124 ; cellular energetics', 'tumor promoting inflammation &amp; # 124 ; enabling replicative immortality', 'tumor promoting inflammation &amp; # 124 ; genomic instability and mutation', 'tumor promoting inflammation &amp; # 124 ; sustaining proliferative signaling'] will be ignored\n",
            "  warnings.warn(\n",
            "0.8335179776412528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# relation extraction on (KD-DTI)"
      ],
      "metadata": {
        "id": "aZzubGubFqEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BioGPT/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw-xuvPsiCNe",
        "outputId": "cadcae6d-60fc-4a6a-9ce2-19ad32414489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT/checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd checkpoints\n",
        "!wget https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/RE-DTI-BioGPT.tgz\n",
        "!tar -zxvf RE-DTI-BioGPT.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA9Jg5umiDWl",
        "outputId": "27d57164-1c58-4fb3-ecff-37244b47c959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: checkpoints: No such file or directory\n",
            "--2023-04-12 04:01:20--  https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/RE-DTI-BioGPT.tgz\n",
            "Resolving msramllasc.blob.core.windows.net (msramllasc.blob.core.windows.net)... 20.209.34.164\n",
            "Connecting to msramllasc.blob.core.windows.net (msramllasc.blob.core.windows.net)|20.209.34.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3960967808 (3.7G) [application/octet-stream]\n",
            "Saving to: ‘RE-DTI-BioGPT.tgz’\n",
            "\n",
            "RE-DTI-BioGPT.tgz   100%[===================>]   3.69G  4.91MB/s    in 10m 22s \n",
            "\n",
            "2023-04-12 04:11:43 (6.08 MB/s) - ‘RE-DTI-BioGPT.tgz’ saved [3960967808/3960967808]\n",
            "\n",
            "RE-DTI-BioGPT/\n",
            "RE-DTI-BioGPT/checkpoint_avg.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BioGPT/examples/RE-DTI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmZSUeRliQSr",
        "outputId": "0fb8b844-8b20-4e00-a641-fccd0b66fc09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BioGPT/examples/RE-DTI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash preprocess.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgRhpvd0GKhO",
        "outputId": "24fc3b94-06f8-4c1c-b945-35aa39eb66b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12097 samples in ../../data/KD-DTI/raw/train.json has been processed with 0 samples has no triples extracted.\n",
            "1000 samples in ../../data/KD-DTI/raw/valid.json has been processed with 0 samples has no triples extracted.\n",
            "1159 samples in ../../data/KD-DTI/raw/test.json has been processed with 0 samples has no triples extracted.\n",
            "Preprocessing train\n",
            "Can't open perl script \"/scripts/tokenizer/tokenizer.perl\": No such file or directory\n",
            "Can't open perl script \"/scripts/tokenizer/tokenizer.perl\": No such file or directory\n",
            "preprocess.sh: line 27: /fast: No such file or directory\n",
            "preprocess.sh: line 28: /fast: No such file or directory\n",
            "Preprocessing valid\n",
            "Can't open perl script \"/scripts/tokenizer/tokenizer.perl\": No such file or directory\n",
            "Can't open perl script \"/scripts/tokenizer/tokenizer.perl\": No such file or directory\n",
            "preprocess.sh: line 27: /fast: No such file or directory\n",
            "preprocess.sh: line 28: /fast: No such file or directory\n",
            "Preprocessing test\n",
            "Can't open perl script \"/scripts/tokenizer/tokenizer.perl\": No such file or directory\n",
            "Can't open perl script \"/scripts/tokenizer/tokenizer.perl\": No such file or directory\n",
            "preprocess.sh: line 27: /fast: No such file or directory\n",
            "preprocess.sh: line 28: /fast: No such file or directory\n",
            "2023-04-12 04:12:39.609855: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-12 04:12:41.469367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-12 04:12:45 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-04-12 04:12:46 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='x', target_lang='y', trainpref='../../data/KD-DTI/raw/relis_train.tok.bpe', validpref='../../data/KD-DTI/raw/relis_valid.tok.bpe', testpref='../../data/KD-DTI/raw/relis_test.tok.bpe', align_suffix=None, destdir='../../data/KD-DTI/relis-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../../data/KD-DTI/raw/dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=8, dict_only=False)\n",
            "2023-04-12 04:12:46 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-preprocess\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fairseq_cli/preprocess.py\", line 389, in cli_main\n",
            "    main(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fairseq_cli/preprocess.py\", line 372, in main\n",
            "    _make_all(args.source_lang, src_dict, args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fairseq_cli/preprocess.py\", line 185, in _make_all\n",
            "    _make_dataset(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fairseq_cli/preprocess.py\", line 178, in _make_dataset\n",
            "    _make_binary_dataset(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fairseq_cli/preprocess.py\", line 119, in _make_binary_dataset\n",
            "    final_summary = FileBinarizer.multiprocess_dataset(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fairseq/binarizer.py\", line 100, in multiprocess_dataset\n",
            "    offsets = find_offsets(input_file, num_workers)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fairseq/file_chunker_utils.py\", line 25, in find_offsets\n",
            "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../../data/KD-DTI/raw/relis_train.tok.bpe.x'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash train.sh"
      ],
      "metadata": {
        "id": "H_q5aXaAGM5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash infer.sh"
      ],
      "metadata": {
        "id": "gyJgbU_LGOHf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}